{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Pipeline\n",
    "Using what you learning about pipelining, rewrite your machine learning code from the last section to use sklearn's Pipeline. For reference, the previous main function implementation is provided in the second to last cell. Refactor this in the last cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ziaeeamir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ziaeeamir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ziaeeamir\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    df = pd.read_csv('../dataset/corporate_messaging.csv', encoding = 'latin-1')\n",
    "    df = df[(df[\"category:confidence\"]== 1) & (df['category'] != 'Exclude')]\n",
    "    X = df.text.values\n",
    "    y = df.category.values\n",
    "    return X,y\n",
    "\n",
    "def tokenize(text):\n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, \"urlplaceholder\")\n",
    "        \n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "        \n",
    "    return clean_tokens\n",
    "\n",
    "def display_results(y_test,y_pred):\n",
    "    labels = np.unique(y_pred)\n",
    "    confusion_mat =  confusion_matrix(y_test, y_pred, labels=labels)\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "    print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_main():\n",
    "    X, y = load_data()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    vect = CountVectorizer(tokenizer=tokenize)\n",
    "    tfidf = TfidfTransformer()\n",
    "    clf = RandomForestClassifier()\n",
    "\n",
    "    # train classifier\n",
    "    X_train_counts = vect.fit_transform(X_train)\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train_counts)\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # predict on test data\n",
    "    X_test_counts = vect.transform(X_test)\n",
    "    X_test_tfidf = tfidf.transform(X_test_counts)\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "    # display results\n",
    "    display_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['Action' 'Dialogue' 'Information']\n",
      "Confusion Matrix:\n",
      " [[ 87   0  26]\n",
      " [  2  27   5]\n",
      " [ 10   2 442]]\n",
      "Accuracy: 0.9251247920133111\n"
     ]
    }
   ],
   "source": [
    "old_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rewrite the main function to use sklearn's `Pipeline` here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    X, y = load_data()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    # build pipeline\n",
    "    pipeline = Pipeline([\n",
    "                        ('vect',CountVectorizer(tokenizer=tokenize)),\n",
    "                        ('tfidf',TfidfTransformer()),\n",
    "                        ( 'clf',RandomForestClassifier())\n",
    "                        ])\n",
    "         \n",
    "\n",
    "    # train classifier\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # predict on test data\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    # display results\n",
    "    display_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['Action' 'Dialogue' 'Information']\n",
      "Confusion Matrix:\n",
      " [[ 82   0  22]\n",
      " [  1  22   7]\n",
      " [ 15   2 450]]\n",
      "Accuracy: 0.9217970049916805\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
